{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "from polars import col\n",
    "import requests\n",
    "import pulp\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from itertools import combinations \n",
    "import json\n",
    "import re \n",
    "from datetime import datetime\n",
    "from datetime import timezone\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the latest items.json from github\n",
    "def update_items():\n",
    "    response = requests.get(\"https://github.com/ao-data/ao-bin-dumps/raw/refs/heads/master/items.json\")\n",
    "    \n",
    "    if not os.path.exists(\"./data\"): \n",
    "        os.makedirs(\"./data\") \n",
    "    \n",
    "    with open(\"./data/items.json\", mode=\"wb\") as file:\n",
    "        file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use dumped json file to get item stats\n",
    "with open('./data/items.json') as f:\n",
    "    data: dict = json.load(f)\n",
    "\n",
    "\n",
    "# recursively gets all combinations of @uniquename and @weight to populate item data\n",
    "def extract_unique_weight_tuples(data: dict):\n",
    "    tuples: list = []\n",
    "    if isinstance(data, dict):\n",
    "        for key, value in data.items():\n",
    "            if key == \"@uniquename\" and \"@weight\" in data:\n",
    "                if re.search(\"LEVEL[1-8]\", data[\"@uniquename\"]) == None:\n",
    "                    tuples.append((data[\"@uniquename\"], data[\"@weight\"]))\n",
    "                else:\n",
    "                    # for some reason albion data projects expects items with quality to have \n",
    "                    # \"LEVEL1@1\", \"LEVEL2@2\", etc on the name and the game files does not have that\n",
    "                    tuples.append((data[\"@uniquename\"] + f\"@{data[\"@uniquename\"][data[\"@uniquename\"].find(\"LEVEL\") + 5]}\", data[\"@weight\"]))\n",
    "            else:\n",
    "                tuples.extend(extract_unique_weight_tuples(value))\n",
    "    elif isinstance(data, list):\n",
    "        for item in data:\n",
    "            tuples.extend(extract_unique_weight_tuples(item))\n",
    "    return tuples\n",
    "\n",
    "def format_tuples_as_dict(tuples):\n",
    "    return {tuple[0]: tuple[1] for tuple in tuples}\n",
    "\n",
    "weight_dicts: dict = format_tuples_as_dict(extract_unique_weight_tuples(data))\n",
    "\n",
    "list_of_items = list(weight_dicts.keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lista_tabelas: list = []\n",
    "locations: str = \"Lymhurst,Bridgewatch,Fort Sterling,Martlock,Thetford\"\n",
    "\n",
    "items_string: str = \"\"\n",
    "index: int = 0\n",
    "links: list = []\n",
    "# The api url has a limit of 4096 chars, so we need to subdivide the call to have only so many items\n",
    "item_string_size_limit = 3900\n",
    "while index < len(list_of_items):\n",
    "    while len(items_string) <= item_string_size_limit:\n",
    "        items_string += f\"{list_of_items[index]},\"\n",
    "        index += 1\n",
    "        if index == len(list_of_items): \n",
    "            break\n",
    "    \n",
    "    link = f\"https://west.albion-online-data.com/api/v2/stats/prices/{items_string}?locations={locations}&qualities=1\"\n",
    "    links.append(link)\n",
    "    items_string = \"\"\n",
    "    \n",
    "    \n",
    "# defines the function to get the request content, useful for parallelize\n",
    "# uses gzip to not tax the server\n",
    "my_headers: dict = {'accept-encoding':'gzip'}\n",
    "def get_data(url: str):\n",
    "    content = requests.get(url, json=True, headers=my_headers).content\n",
    "    return content\n",
    "\n",
    "# get all json results in paralel\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    conteudos =  list(executor.map(get_data, links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ignores rows with 0 price, as those mean none is getting sold\n",
    "for conteudo in conteudos:\n",
    "    tabela = pl.read_json(conteudo)\n",
    "\n",
    "    lista_tabelas.append(tabela)\n",
    "\n",
    "resorce_list: list = [\"_WOOD_\", \"_STONE_\", \"_HIDE_\", \"_ORE_\", \"_FIBER_\", \"_PLANKS_\", \"_BRICK_\", \"_LEATHER_\", \"_METAL_\", \"_CLOTH_\", \"_SOUL_\", \"_RUNE_\"]\n",
    "time_now: datetime = datetime.now(tz=timezone.utc)#.replace(tzinfo=None)\n",
    "\n",
    "# The polars lazy api is generally faster\n",
    "final = pl.concat(lista_tabelas).lazy().select(\n",
    "    col(\"city\"),\n",
    "    col(\"sell_price_min\"),\n",
    "    col(\"sell_price_max\"),\n",
    "    col(\"buy_price_min\"),\n",
    "    col(\"buy_price_max\"),\n",
    "    col(\"sell_price_min_date\").str.to_datetime(),\n",
    "    # each quality of an item is basically a new item for this purpose, \n",
    "    # so it's better to concat item and quality\n",
    "    item_name = pl.concat_str([\n",
    "        col(\"item_id\"),\n",
    "        col(\"quality\"),\n",
    "    ], separator = \"_\"),\n",
    "    buy_price_mean = ((col(\"sell_price_min\") + col(\"sell_price_max\")) /2) ,\n",
    "    sell_price_mean = ((col(\"buy_price_min\") + col(\"buy_price_max\")) /2),\n",
    "    buy_price_max_age =  (time_now - col(\"buy_price_max_date\").str.to_datetime().dt.replace_time_zone(\"UTC\")).dt.total_minutes(),\n",
    "    sell_price_min_age =  (time_now - col(\"buy_price_min_date\").str.to_datetime().dt.replace_time_zone(\"UTC\")).dt.total_minutes(),\n",
    ").with_columns(\n",
    "    resource_tag = pl.when(col(\"item_name\").str.contains_any(resorce_list)).then(True).otherwise(False)\n",
    ")\n",
    "\n",
    "\n",
    "teste = final.collect()\n",
    "final.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cities: list = [\"Bridgewatch\", \"Martlock\", \"Thetford\", \"Fort Sterling\", \"Lymhurst\", \"Bridgewatch\"]\n",
    "\n",
    "# will be a configurable value for how old the information can be\n",
    "max_age: int = 120\n",
    "\n",
    "# crete the combinations 2 by 2\n",
    "city_combinations: list = list(combinations(cities, 2))\n",
    "per_comb: list= []\n",
    "\n",
    "products = final.collect().get_column(\"item_name\").unique().to_list()\n",
    "\n",
    "# This ugly loop would probably be better with .map() sintax and\n",
    "# possibly tuples or structs, at least its not that slow\n",
    "for comb in city_combinations:\n",
    "    orig, dest = comb\n",
    "    products_list: list = []\n",
    "    buy_prices: list = []\n",
    "    profits: list = []\n",
    "    weights: list = []\n",
    "    tags: list = []\n",
    "    ages: list = []\n",
    "    filtered_by_cities = final.filter(col(\"city\").is_in([orig, dest]))\n",
    "    # massaging the data into dicts gives a huge speed up\n",
    "    buy = dict(filtered_by_cities.filter(col(\"city\") == orig).select([\"item_name\", \"sell_price_min\"]).collect().iter_rows())\n",
    "    buy_ages = dict(filtered_by_cities.filter(col(\"city\") == orig).select([\"item_name\", \"sell_price_min_age\"]).collect().iter_rows())\n",
    "    sell = dict(filtered_by_cities.filter(col(\"city\") == dest).select([\"item_name\", \"buy_price_max\"]).collect().iter_rows())\n",
    "    sell_ages = dict(filtered_by_cities.filter(col(\"city\") == dest).select([\"item_name\", \"buy_price_max_age\"]).collect().iter_rows())\n",
    "    tag = dict(filtered_by_cities.filter(col(\"city\") == dest).select([\"item_name\", \"resource_tag\"]).collect().iter_rows())\n",
    "\n",
    "    for p in products:\n",
    "        buy_price: int = buy[p]\n",
    "        buy_age: int = buy_ages[p]\n",
    "        sell_price: int = sell[p]\n",
    "        sell_age: int = sell[p]\n",
    "        if buy_price > 0 and sell_price > 0 and buy_age <= max_age and sell_age <= max_age:\n",
    "            products_list.append(f\"{orig}_{dest}_{p}\")\n",
    "            buy_prices.append(buy_price)\n",
    "            profits.append(sell_price-buy_price)\n",
    "            weights.append(float(weight_dicts[p[0:-2]]))\n",
    "            tags.append(tag[p])\n",
    "            ages.append((buy_age, sell_age))\n",
    "\n",
    "    per_comb.append((products_list, buy_prices, profits, weights, tags, ages))\n",
    "\n",
    "\n",
    "per_comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these 4 will be configurable\n",
    "max_weight = 4116 # default weight of t8 ox \n",
    "silver_limit = 500_000\n",
    "resource_limit = 1000\n",
    "non_resource_limit = 10 # non resources are riskier\n",
    "\n",
    "for comb in per_comb:\n",
    "    # sometimes there will not be any items that are not too old, in this case we skip the iteration\n",
    "    if len(comb[0]) == 0: continue \n",
    "\n",
    "    products_list, buy_prices, profits, weights, tags, ages = comb\n",
    "\n",
    "\n",
    "    # Create a PuLP problem instance as an Integer Linear Program (ILP)\n",
    "    prob = pulp.LpProblem(\"MaximizeProfit\", pulp.LpMaximize)\n",
    "\n",
    "    # Create decision variables for each product \n",
    "    x = pulp.LpVariable.dicts(\"Product\", products_list, cat=pulp.LpInteger, lowBound=0)\n",
    "    y = pulp.LpVariable.dicts(\"PurchaseLimit\", products_list, cat=pulp.LpInteger, lowBound=0)  # New decision variable for purchase limit\n",
    "\n",
    "\n",
    "    # Set the objective function (maximize profit)\n",
    "    prob += pulp.lpSum([profits[i] * x[products_list[i]] for i in range(len(products_list))])\n",
    "\n",
    "    # Add the budget constraint\n",
    "    prob += pulp.lpSum([buy_prices[i] * x[products_list[i]] for i in range(len(products_list))]) <= silver_limit\n",
    "\n",
    "    # Add the weight constraint\n",
    "    prob += pulp.lpSum([weights[i] * x[products_list[i]] for i in range(len(products_list))]) <= max_weight\n",
    "\n",
    "    # user should be able the max to buy of resources and non resources,\n",
    "    # this limit is added here\n",
    "    for i in range(len(products_list)):\n",
    "        if tags[i]:\n",
    "            y[products_list[i]].upBound = resource_limit\n",
    "        else:\n",
    "            y[products_list[i]].upBound = non_resource_limit\n",
    "\n",
    "    for i in range(len(products_list)):\n",
    "        prob += y[products_list[i]] >= x[products_list[i]]\n",
    "\n",
    "    # Solve the problem\n",
    "    #solver_list = pulp.listSolvers(onlyAvailable=True)\n",
    "    #print(solver_list)\n",
    "    pulp.GLPK_CMD(msg=False).solve(prob)\n",
    "\n",
    "\n",
    "    # Print the solution\n",
    "    print(\"Solution:\")\n",
    "    for i in range(len(products_list)):\n",
    "        if x[products_list[i]].value() > 0:\n",
    "            print(f\"Product {products_list[i]} is selected: {x[products_list[i]].value()} units and {int(profits[i])} profit per\")\n",
    "            print(f\"ages: {ages[i]} minutes\")\n",
    "    print(f\"Total profit: {int(pulp.value(prob.objective)):,d}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
